{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_qdrant import FastEmbedSparse, RetrievalMode\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "\n",
    "from mlops_agents.agent import MlOpsAgent\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ca94bd8e7f47569737eaeafe902e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 29 files:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text:v1.5\"\n",
    ")\n",
    "\n",
    "sparse_embeddings = FastEmbedSparse(\n",
    "    model_name=\"Qdrant/bm25\"\n",
    ")\n",
    "\n",
    "qdrant = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=embeddings,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    url=QDRANT_URL,\n",
    "    prefer_grpc=True,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    collection_name=\"mlops_document\",\n",
    "    retrieval_mode=RetrievalMode.HYBRID,\n",
    ")\n",
    "\n",
    "hybrid_rerank_qdrant_retriever = qdrant.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs={\"k\": 20},\n",
    ")\n",
    "\n",
    "groq_llama3_1_70b = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0,\n",
    "    api_key=GROQ_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlops_agent = MlOpsAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**What is Data Leakage?**\n",
      "\n",
      "Data leakage refers to the phenomenon where a form of the label or target variable \"leaks\" into the set of features used for making predictions, and this same information is not available during inference. This can cause machine learning models to fail in unexpected and spectacular ways, even after extensive evaluation and testing.\n",
      "\n",
      "**Examples of Data Leakage**\n",
      "\n",
      "1. **Predicting COVID-19 risks from medical scans**: A model was trained on a mix of scans taken when patients were lying down and standing up. The model learned to predict serious COVID-19 risk from a person's position, which is not a relevant feature for making predictions.\n",
      "2. **Predicting COVID-19 risks from text font**: A model was trained on scans labeled with different fonts from various hospitals. The model learned to predict COVID-19 risk from the font used, which is not a relevant feature for making predictions.\n",
      "3. **Predicting lung cancer from CT scans**: A model was trained on CT scans from hospital A, which used a specific scan machine for patients with suspected lung cancer. The model learned to rely on the information on the scan machine used to make predictions, which is not available in hospital B.\n",
      "\n",
      "**Common Causes of Data Leakage**\n",
      "\n",
      "1. **Splitting time-correlated data randomly**: Randomly splitting data into training, validation, and test sets can lead to data leakage if the data is time-correlated.\n",
      "2. **Data duplication prior to splitting**: Including duplicate data points in the training and test sets can lead to data leakage.\n",
      "3. **Leakage from data generation process**: Information about the data generation process can leak into the features used for making predictions.\n",
      "4. **Scaling before splitting**: Scaling data before splitting it into training and test sets can lead to data leakage.\n",
      "\n",
      "**Detecting Data Leakage**\n",
      "\n",
      "1. **Measure the predictive power of each feature**: Investigate features with unusually high correlation with the target variable.\n",
      "2. **Monitor for data leakage during the entire lifecycle of an ML project**: Data leakage can happen during many steps, from generating, collecting, sampling, splitting, and processing data to feature engineering.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is data leakage ?\"\n",
    "graph_state = {\n",
    "    \"question\":question,\n",
    "    \"rag_answer\":\"None\",\n",
    "    \"supervisor_route_choice\":\"None\",\n",
    "    \"hybrid_rerank_qdrant_retriever\":hybrid_rerank_qdrant_retriever,\n",
    "    \"groq_llama3_1_70b\": groq_llama3_1_70b\n",
    "}\n",
    "result = mlops_agent(graph_state)\n",
    "print(result['rag_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [],\n",
       " 'question': 'What is data leakage ?',\n",
       " 'rag_answer': '**What is Data Leakage?**\\n\\nData leakage refers to the phenomenon where a form of the label or target variable \"leaks\" into the set of features used for making predictions, and this same information is not available during inference. This can cause machine learning models to fail in unexpected and spectacular ways, even after extensive evaluation and testing.\\n\\n**Examples of Data Leakage**\\n\\n1. **Predicting COVID-19 risks from medical scans**: A model was trained on a mix of scans taken when patients were lying down and standing up. The model learned to predict serious COVID-19 risk from a person\\'s position, which is not a relevant feature for making predictions.\\n2. **Predicting COVID-19 risks from text font**: A model was trained on scans labeled with different fonts from various hospitals. The model learned to predict COVID-19 risk from the font used, which is not a relevant feature for making predictions.\\n3. **Predicting lung cancer from CT scans**: A model was trained on CT scans from hospital A, which used a specific scan machine for patients with suspected lung cancer. The model learned to rely on the information on the scan machine used to make predictions, which is not available in hospital B.\\n\\n**Common Causes of Data Leakage**\\n\\n1. **Splitting time-correlated data randomly**: Randomly splitting data into training, validation, and test sets can lead to data leakage if the data is time-correlated.\\n2. **Data duplication prior to splitting**: Including duplicate data points in the training and test sets can lead to data leakage.\\n3. **Leakage from data generation process**: Information about the data generation process can leak into the features used for making predictions.\\n4. **Scaling before splitting**: Scaling data before splitting it into training and test sets can lead to data leakage.\\n\\n**Detecting Data Leakage**\\n\\n1. **Measure the predictive power of each feature**: Investigate features with unusually high correlation with the target variable.\\n2. **Monitor for data leakage during the entire lifecycle of an ML project**: Data leakage can happen during many steps, from generating, collecting, sampling, splitting, and processing data to feature engineering.',\n",
       " 'supervisor_route_choice': 'vector_store_agent',\n",
       " 'hybrid_rerank_qdrant_retriever': VectorStoreRetriever(tags=['QdrantVectorStore', 'OllamaEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x000002938B414D40>, search_kwargs={'k': 20}),\n",
       " 'groq_llama3_1_70b': ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002938C6F05C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002938C6F10A0>, model_name='llama-3.1-70b-versatile', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********'))}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "user_query = \"What is data distribution drift?\"\n",
    "\n",
    "url = \"http://127.0.0.1:8000/chatResponse\"  # Replace with your server URL if deployed\n",
    "\n",
    "# Define the JSON payload\n",
    "payload = {\n",
    "    \"user_query\": user_query\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "response = requests.post(url, json=payload).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data distribution drift refers to a change in the underlying distribution of the data, which can affect the performance of a machine learning model. This can occur in various forms, including:\n",
      "\n",
      "1. **Covariate shift**: When the probability density of the input (P(X)) changes, but the conditional probability of the output given the input (P(Y|X)) remains the same.\n",
      "2. **Label shift**: When the probability density of the output (P(Y)) changes, but the conditional probability of the input given the output (P(X|Y)) remains the same.\n",
      "3. **Concept drift**: When the conditional probability of the output given the input (P(Y|X)) changes, but the probability density of the input (P(X)) remains the same.\n",
      "\n",
      "Data distribution drift can be detected by monitoring the model's performance metrics, such as accuracy, F1 score, recall, and AUC-ROC, in production. However, when ground truth labels are unavailable or delayed, other distributions of interest can be monitored, including the input distribution (P(X)), label distribution (P(Y)), and conditional distributions (P(X|Y) and P(Y|X)).\n",
      "\n",
      "It's worth noting that data distribution drift can occur in multiple forms simultaneously, making it more challenging to handle.\n"
     ]
    }
   ],
   "source": [
    "print(response['response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaredllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
