{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_qdrant import FastEmbedSparse, RetrievalMode\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910b87d1c89045248eef2cd8a88d1644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 29 files:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = config.QDRANT_URL\n",
    "api_key = config.QDRANT_API_KEY\n",
    "\n",
    "# Initialize text embeddings\n",
    "# model_name = \"jinaai/jina-embeddings-v3\"\n",
    "# model_kwargs = {'device': 'cuda', \"trust_remote_code\":True}\n",
    "# encode_kwargs = {'normalize_embeddings': True, 'task': 'retrieval.query'}\n",
    "# embeddings =  HuggingFaceEmbeddings(\n",
    "#     model_name=model_name,\n",
    "#     model_kwargs=model_kwargs,\n",
    "#     encode_kwargs=encode_kwargs\n",
    "# )\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text:v1.5\"\n",
    ")\n",
    "\n",
    "sparse_embeddings = FastEmbedSparse(\n",
    "    model_name=\"Qdrant/bm25\"\n",
    ")\n",
    "\n",
    "qdrant = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=embeddings,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    url=url,\n",
    "    prefer_grpc=True,\n",
    "    api_key=api_key,\n",
    "    collection_name=\"mlops_document\",\n",
    "    retrieval_mode=RetrievalMode.HYBRID,\n",
    ")\n",
    "\n",
    "hybrid_qdrant_retriever = qdrant.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "hybrid_rerank_qdrant_retriever = qdrant.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs={\"k\": 20},\n",
    ")\n",
    "\n",
    "rag_fusion_qdrant_retriever = qdrant.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs={\"k\": 5},\n",
    ")\n",
    "\n",
    "groq_llama3_1_70b = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0,\n",
    "    api_key=config.GROQ_API_KEY\n",
    ")\n",
    "\t\n",
    "groq_gemma_9b = ChatGroq(\n",
    "    model=\"gemma2-9b-it\",\n",
    "    temperature=0,\n",
    "    api_key=config.GROQ_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define Graph State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "class GraphState(MessagesState):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    doc_context: str\n",
    "    generation: str\n",
    "    rag_variant: str\n",
    "    hallucination: str\n",
    "    hallucination_reason: str\n",
    "    generate_count: int\n",
    "    max_generate_count: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Helper Function, Nodes and Conditional Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_docs(retrieved_docs: list[list], top_k:int, question:str):\n",
    "\n",
    "    flattened_docs = [doc for docs in retrieved_docs for doc in docs]\n",
    "\n",
    "    flash_reranker = FlashrankRerank(\n",
    "        model=\"ms-marco-MiniLM-L-12-v2\",\n",
    "        top_n=top_k\n",
    "    )\n",
    "\n",
    "    top_docs = flash_reranker.compress_documents(\n",
    "        documents=flattened_docs, query=question\n",
    "    )\n",
    "\n",
    "    return top_docs\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Define Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag supervisor node\n",
    "def rag_supervisor(state):\n",
    "    question = state['question']\n",
    "\n",
    "    # Data model\n",
    "    class RagSelection(BaseModel):\n",
    "        \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "        rag_choice: Literal[\"hybrid_search_rerank\", \"rag_fusion\"] = Field(\n",
    "            description=\"Given a user question choose to route it to hybrid_search_rerank or rag_fusion. \",\n",
    "        )\n",
    "\n",
    "\n",
    "    # LLM with structured output\n",
    "    rag_supervisor_llm = groq_llama3_1_70b.with_structured_output(RagSelection)\n",
    "\n",
    "    # Prompt\n",
    "    system = \"\"\"You are an expert at routing a user question to a specific RAG variant based on the complexity of the question.\n",
    "    If the question is simple, route it to hybrid_search_rerank.\n",
    "    If the question is complex, router it to rag_fusion.\n",
    "\n",
    "    Example:\n",
    "    Question: What is data drift ? \n",
    "    route: hybrid_search_rerank\n",
    "\n",
    "    Example:\n",
    "    Question: What is data drift? how does it happen ? how to detect it and how to solve it \n",
    "    route: rag_fusion\n",
    "    \"\"\"\n",
    "    route_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    rag_supervisor_agent = route_prompt | rag_supervisor_llm\n",
    "\n",
    "    agent_choice = rag_supervisor_agent.invoke(question)\n",
    "\n",
    "    return {\"rag_variant\": agent_choice.rag_choice}\n",
    "\n",
    "# Retrieval Node for hybrid search reranker\n",
    "def hybrid_reranker_retrieval(state):\n",
    "    question = state['question']\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # 1. Retrieval\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    compressor = FlashrankRerank(\n",
    "        model=\"ms-marco-MiniLM-L-12-v2\",\n",
    "        top_n=4\n",
    "    )\n",
    "    \n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor, base_retriever=hybrid_rerank_qdrant_retriever\n",
    "    )\n",
    "\n",
    "    retrieved_docs = compression_retriever.invoke(question)\n",
    "\n",
    "    doc_context = format_docs(retrieved_docs)\n",
    "\n",
    "    return {\"doc_context\": doc_context}\n",
    "\n",
    "# Retrieval Node for rag fusion\n",
    "def rag_fusion_retrieval(state):\n",
    "    question = state['question']\n",
    "    \n",
    "    # ----------------------------------------------------------------\n",
    "    # 1. Query Generation\n",
    "    # ----------------------------------------------------------------\n",
    "    # RAG-Fusion: Related\n",
    "    template = \"\"\"\n",
    "    You are an intelligent assistant that specializes in breaking down complex queries into simpler, manageable subqueries. \n",
    "    Generate exactly 4 focused search queries that each address a unique aspect of the following question: {question}\n",
    "    Provide only the search queries as individual questions, and do not include any additional text or explanations.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_rag_fusion = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    llm = groq_llama3_1_70b\n",
    "\n",
    "    generate_queries = (\n",
    "        prompt_rag_fusion \n",
    "        | llm\n",
    "        | StrOutputParser() \n",
    "        | (lambda x: x.split(\"\\n\"))\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # 2. Retrieval\n",
    "    # ----------------------------------------------------------------\n",
    "    retrieval_chain_rag_fusion = generate_queries | rag_fusion_qdrant_retriever.map() \n",
    "\n",
    "    retrieved_docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "\n",
    "    top_docs = get_top_docs(retrieved_docs=retrieved_docs, top_k=4, question=question)\n",
    "\n",
    "    doc_context = format_docs(top_docs)\n",
    "\n",
    "    return {\"doc_context\": doc_context}\n",
    "\n",
    "\n",
    "def answer_generator(state):\n",
    "    question = state['question']\n",
    "    doc_context = state['doc_context']\n",
    "    generate_count = state['generate_count']\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # 2. Generation\n",
    "    # -----------------------------------------------------------------\n",
    "    # Prompt\n",
    "    generate_template = \"\"\"\n",
    "    You are an assistant for question-answering tasks. \n",
    "    Please answer the question based on the context provided.\n",
    "    Do not tell the user that you are referring to the context to answer the question \n",
    "    If you don't know the answer or the context does not answer the question, just say that you don't know. \n",
    "    Elaborate your answer in well structured format.\n",
    "\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    regenerate_template = \"\"\"\n",
    "    You are an assistant for question-answering tasks. It seems the previous answer may have included information not fully supported by the provided context.\\n\n",
    "    Please answer the question strictly based on the context provided. Do not introduce information that is not explicitly stated in the context.\\n\n",
    "    If the context does not fully answer the question or you don’t know the answer, state that you don’t know.\\n\n",
    "    Elaborate your answer in well structured format.\n",
    "    Do not tell the user you are referring to the context to answer question.\\n\n",
    "\n",
    "    Question: {question}\n",
    "    Context: {context}\n",
    "    Revised Answer:\n",
    "    \"\"\"\n",
    "    if generate_count == 0:\n",
    "        prompt = ChatPromptTemplate.from_template(generate_template)\n",
    "    else:\n",
    "        prompt = ChatPromptTemplate.from_template(regenerate_template)\n",
    "\n",
    "    \n",
    "    llm = groq_llama3_1_70b\n",
    "\n",
    "    rag_chain = (\n",
    "        prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    generated_answer = rag_chain.invoke({\"question\":question, \"context\":doc_context})\n",
    "\n",
    "    generate_count += 1\n",
    "\n",
    "    return {'generation': generated_answer, \"generate_count\": generate_count}\n",
    "\n",
    "def hallucination_grader(state):\n",
    "    generated_answer = state['generation']\n",
    "    doc_context = state['doc_context']\n",
    "\n",
    "    # Data model\n",
    "    class GradeHallucinations(BaseModel):\n",
    "        \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "        binary_score: Literal[\"yes\", \"no\"] = Field(\n",
    "            description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "        )\n",
    "\n",
    "        hallucination_reason: str = Field(\n",
    "            description=\"Justification for why hallucination happen or not happen.\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # LLM with structured output\n",
    "    llm = groq_gemma_9b\n",
    "    structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "    # Prompt\n",
    "    system = \"\"\"\n",
    "    You are a grader evaluating whether a response generated by a language model is accurately grounded in and supported by a provided set of retrieved facts. \n",
    "    Return 'yes' if the response is grounded in the retrieved facts.\n",
    "    Return 'no' if the response is not grounded in the retrieved facts.\n",
    "    \"\"\"\n",
    "\n",
    "    hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "    hallucination_grade = hallucination_grader.invoke({\"documents\": doc_context, \"generation\": generated_answer})\n",
    "\n",
    "    return {\"hallucination\": hallucination_grade.binary_score, \"hallucination_reason\": hallucination_grade.hallucination_reason}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Define Conditional Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_supervisor_route(state): \n",
    "    retrieval_choice = state['rag_variant']\n",
    "\n",
    "    if retrieval_choice == \"hybrid_search_rerank\":\n",
    "        return \"hybrid_search_rerank\"\n",
    "    \n",
    "    elif retrieval_choice == \"rag_fusion\":\n",
    "        return \"rag_fusion\"\n",
    "\n",
    "def regenerate_route(state):\n",
    "    hallucination = state['hallucination']\n",
    "    generate_count = state['generate_count']\n",
    "    max_generate_count = state['max_generate_count']\n",
    "\n",
    "    if (hallucination.lower() == \"no\") and (generate_count < max_generate_count):\n",
    "        return \"regenerate\"\n",
    "    else:\n",
    "        return \"end\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# Initialise the graph\n",
    "rag_workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "rag_workflow.add_node(\"rag_supervisor\", rag_supervisor)\n",
    "rag_workflow.add_node(\"hybrid_reranker_retrieval\", hybrid_reranker_retrieval)\n",
    "rag_workflow.add_node(\"rag_fusion_retrieval\", rag_fusion_retrieval)\n",
    "rag_workflow.add_node(\"answer_generator\", answer_generator)\n",
    "rag_workflow.add_node(\"hallucination_grader\", hallucination_grader)\n",
    "\n",
    "# Add Edges\n",
    "rag_workflow.set_entry_point(\"rag_supervisor\")\n",
    "rag_workflow.add_conditional_edges(\n",
    "    source=\"rag_supervisor\",\n",
    "    path=rag_supervisor_route,\n",
    "    path_map={\n",
    "        \"hybrid_search_rerank\": \"hybrid_reranker_retrieval\",\n",
    "        \"rag_fusion\": \"rag_fusion_retrieval\"\n",
    "    }\n",
    ")\n",
    "rag_workflow.add_edge(\"hybrid_reranker_retrieval\", \"answer_generator\")\n",
    "rag_workflow.add_edge(\"rag_fusion_retrieval\", \"answer_generator\")\n",
    "rag_workflow.add_edge(\"answer_generator\", \"hallucination_grader\")\n",
    "rag_workflow.add_conditional_edges(\n",
    "    source=\"hallucination_grader\",\n",
    "    path=regenerate_route,\n",
    "    path_map={\n",
    "        \"regenerate\": \"answer_generator\",\n",
    "        \"end\":END\n",
    "    }\n",
    ")\n",
    "adaptive_rag = rag_workflow.compile()\n",
    "\n",
    "display(Image(adaptive_rag.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "question = \"latency happen if too many features ? \"\n",
    "result = adaptive_rag.invoke({\"question\": question, \"generate_count\":0, \"max_generate_count\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency can indeed happen if too many features are used in a machine learning model. This is because having too many features can increase the memory required to serve a model, which can lead to higher latency. \n",
      "\n",
      "Here's a breakdown of how too many features can lead to higher latency:\n",
      "\n",
      "1. **Increased memory requirements**: When a model has too many features, it requires more memory to store and process these features. This can lead to slower inference times, which can result in higher latency.\n",
      "2. **Slower inference times**: With more features, the model takes longer to process each query, which can lead to slower inference times. This can be particularly problematic in applications with strict latency requirements.\n",
      "3. **Overfitting and data leakage**: Having too many features can also lead to overfitting and data leakage, which can further exacerbate the latency issue.\n",
      "\n",
      "To mitigate these issues, it's essential to carefully select the features used in the model and to perform ablation studies to determine the importance of each feature. This can help to identify and remove unnecessary features, which can lead to faster inference times and lower latency.\n"
     ]
    }
   ],
   "source": [
    "print(result['generation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Generate answer and retrieve the referred context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 12 threads.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "adaptive_rag_test = joblib.load(filename=\"test_cases.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def answer_question_adaptive_rag(\n",
    "    test_cases: dict,\n",
    "    question_key: str,\n",
    "    answer_key: str,\n",
    "    doc_context_key: str,\n",
    ") -> dict:\n",
    "    test_cases[answer_key] = []\n",
    "    test_cases[doc_context_key] = []\n",
    "\n",
    "    for question in tqdm(test_cases[question_key], desc=\"Answering questions\", total=len(test_cases[question_key])):\n",
    "        result = adaptive_rag.invoke({\"question\": question, \"generate_count\":0, \"max_generate_count\":2})\n",
    "        llm_answer = result['generation']\n",
    "        doc_context = result['doc_context']\n",
    "        time.sleep(5)\n",
    "\n",
    "        test_cases[answer_key].append(llm_answer)\n",
    "        test_cases[doc_context_key].append(doc_context)\n",
    "    return test_cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:   5%|▌         | 1/20 [00:11<03:37, 11.46s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 4.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  10%|█         | 2/20 [00:30<04:49, 16.11s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 12.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  15%|█▌        | 3/20 [00:55<05:41, 20.07s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 21.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  20%|██        | 4/20 [01:28<06:43, 25.25s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 5.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  25%|██▌       | 5/20 [01:47<05:42, 22.83s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 3.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 17.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 19.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  30%|███       | 6/20 [02:42<07:51, 33.67s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 14.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 23.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  35%|███▌      | 7/20 [03:35<08:42, 40.20s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 18.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  40%|████      | 8/20 [04:05<07:21, 36.80s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 15.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  45%|████▌     | 9/20 [04:33<06:15, 34.18s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 15.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 20.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  50%|█████     | 10/20 [05:23<06:29, 38.99s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 12.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  55%|█████▌    | 11/20 [05:47<05:10, 34.52s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 17.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  60%|██████    | 12/20 [06:16<04:23, 32.91s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 14.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  65%|██████▌   | 13/20 [06:43<03:36, 30.95s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 13.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  70%|███████   | 14/20 [07:08<02:55, 29.19s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 17.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  75%|███████▌  | 15/20 [07:37<02:26, 29.24s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 18.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 22.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  80%|████████  | 16/20 [08:32<02:27, 36.83s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 7.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  85%|████████▌ | 17/20 [08:51<01:34, 31.52s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 21.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  90%|█████████ | 18/20 [09:24<01:04, 32.08s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 14.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions:  95%|█████████▌| 19/20 [09:51<00:30, 30.28s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 16.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answering questions: 100%|██████████| 20/20 [10:18<00:00, 30.92s/it]\n"
     ]
    }
   ],
   "source": [
    "adaptive_rag_test = answer_question_adaptive_rag(\n",
    "    test_cases=adaptive_rag_test,\n",
    "    question_key=\"question\",\n",
    "    answer_key=\"adaptive_rag_answer\",\n",
    "    doc_context_key=\"adaptive_rag_doc_context\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Data Distribution Shifts**\n",
      "\n",
      "Data distribution shifts refer to changes in the underlying distribution of the data, which can affect the performance of machine learning models. These shifts can occur in various forms, including concept drift, covariate shift, and label shift.\n",
      "\n",
      "**Types of Data Distribution Shifts**\n",
      "\n",
      "1. **Covariate Shift**: This occurs when the distribution of the input data (X) changes, but the conditional probability of the output given the input (P(Y|X)) remains the same. In other words, the input data distribution changes, but the relationship between the input and output remains the same.\n",
      "2. **Label Shift**: This occurs when the distribution of the output data (Y) changes, but the conditional probability of the input given the output (P(X|Y)) remains the same.\n",
      "3. **Concept Drift**: This occurs when the conditional probability of the output given the input (P(Y|X)) changes, but the input data distribution (P(X)) remains the same.\n",
      "\n",
      "**Causes of Data Distribution Shifts**\n",
      "\n",
      "Data distribution shifts can occur due to various reasons, including:\n",
      "\n",
      "* Biases during data selection process\n",
      "* Artificial alteration of training data to make it easier for the model to learn\n",
      "* Changes in the underlying data distribution over time\n",
      "* Differences between training and inference data\n",
      "\n",
      "**Examples of Data Distribution Shifts**\n",
      "\n",
      "1. **Covariate Shift**: In a breast cancer detection model, the input data distribution changes when the model is trained on data from a clinic where women over 40 are more likely to get checkups, but the relationship between age and breast cancer risk remains the same.\n",
      "2. **Label Shift**: In a spam detection model, the output data distribution changes when the model is trained on data from a specific time period, but the relationship between the input features and the output label remains the same.\n",
      "\n",
      "**Importance of Understanding Data Distribution Shifts**\n",
      "\n",
      "Understanding data distribution shifts is crucial for developing efficient algorithms to detect and address these shifts, which can affect the performance of machine learning models in production.\n"
     ]
    }
   ],
   "source": [
    "print(adaptive_rag_test['adaptive_rag_answer'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jthxc\\anaconda3\\envs\\jaredllm\\Lib\\site-packages\\deepeval\\__init__.py:49: UserWarning: You are using deepeval version 1.5.0, however version 1.5.4 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from deepeval.metrics import ContextualPrecisionMetric, ContextualRecallMetric, ContextualRelevancyMetric, AnswerRelevancyMetric, FaithfulnessMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from tqdm import trange\n",
    "\n",
    "class GroqLLM(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model\n",
    "    ):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        return chat_model.invoke(prompt).content\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        res = await chat_model.ainvoke(prompt)\n",
    "        return res.content\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Custom Azure OpenAI Model\"\n",
    "\n",
    "# Replace these with real values\n",
    "custom_model = ChatGroq(\n",
    "    model=\"gemma2-9b-it\",\n",
    "    temperature=0,\n",
    "    api_key=config.GROQ_API_KEY\n",
    ")\n",
    "# Define Critic model\n",
    "groq_critic_llm = GroqLLM(model=custom_model)\n",
    "\n",
    "# Define all metrics\n",
    "contextual_precision = ContextualPrecisionMetric(\n",
    "    threshold=0.7,\n",
    "    model=groq_critic_llm,\n",
    "    include_reason=False\n",
    ")\n",
    "\n",
    "contextual_recall = ContextualRecallMetric(\n",
    "    threshold=0.7,\n",
    "    model=groq_critic_llm,\n",
    "    include_reason=False    \n",
    ")\n",
    "contextual_relevancy = ContextualRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    model=groq_critic_llm,\n",
    "    include_reason=False\n",
    ")\n",
    "\n",
    "answer_relevancy = AnswerRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    model=groq_critic_llm,\n",
    "    include_reason=False\n",
    ")\n",
    "\n",
    "faithfulness = FaithfulnessMetric(\n",
    "    threshold=0.7,\n",
    "    model=groq_critic_llm,\n",
    "    include_reason=False\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate_rag(\n",
    "    rag_test_cases: dict,\n",
    "    answer_relevancy_key: str,\n",
    "    faithfulness_key: str,\n",
    "    contextual_precision_key: str,\n",
    "    contextual_recall_key: str,\n",
    "    contextual_relevancy_key: str,\n",
    "    question_key: str,\n",
    "    expected_answer_key: str,\n",
    "    actual_answer_key: str,\n",
    "    doc_context_key: str\n",
    ") -> dict:\n",
    "\n",
    "    rag_test_cases[answer_relevancy_key] = []\n",
    "    rag_test_cases[faithfulness_key] = []\n",
    "    rag_test_cases[contextual_precision_key] = []\n",
    "    rag_test_cases[contextual_recall_key] = []\n",
    "    rag_test_cases[contextual_relevancy_key] = []\n",
    "\n",
    "    # Evaluate each test case\n",
    "    for i in tqdm(range(len(rag_test_cases[question_key])), desc=\"Evaluating answers\", total=len(rag_test_cases[question_key])):\n",
    "        question = rag_test_cases[question_key][i]\n",
    "        expected_answer = rag_test_cases[expected_answer_key][i]\n",
    "        actual_answer = rag_test_cases[actual_answer_key][i]\n",
    "        doc_context = rag_test_cases[doc_context_key][i]\n",
    "\n",
    "\n",
    "        test_case = LLMTestCase(\n",
    "            input=question,\n",
    "            actual_output=actual_answer,\n",
    "            expected_output=expected_answer,\n",
    "            retrieval_context=[\n",
    "                doc_context\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            answer_relevancy.measure(test_case)\n",
    "            answer_relevancy_score = answer_relevancy.score\n",
    "        except:\n",
    "            answer_relevancy_score = -1\n",
    "        time.sleep(20)\n",
    "\n",
    "        try:\n",
    "            faithfulness.measure(test_case)\n",
    "            faithfulness_score = faithfulness.score\n",
    "        except:\n",
    "            faithfulness_score = -1\n",
    "        time.sleep(20)   \n",
    "\n",
    "        try:\n",
    "            contextual_precision.measure(test_case)\n",
    "            contextual_precision_score = contextual_precision.score\n",
    "        except:\n",
    "            contextual_precision_score = -1\n",
    "        time.sleep(20)\n",
    "\n",
    "        try:\n",
    "            contextual_recall.measure(test_case)\n",
    "            contextual_recall_score = contextual_recall.score\n",
    "        except:\n",
    "            contextual_recall_score = -1\n",
    "        time.sleep(20)\n",
    "\n",
    "        try:\n",
    "            contextual_relevancy.measure(test_case)\n",
    "            contextual_relevancy_score = contextual_relevancy.score\n",
    "        except:\n",
    "            contextual_relevancy_score = -1\n",
    "        time.sleep(20)\n",
    "\n",
    "        rag_test_cases[answer_relevancy_key].append(answer_relevancy_score)\n",
    "        rag_test_cases[faithfulness_key].append(faithfulness_score)\n",
    "        rag_test_cases[contextual_precision_key].append(contextual_precision_score)\n",
    "        rag_test_cases[contextual_recall_key].append(contextual_recall_score)\n",
    "        rag_test_cases[contextual_relevancy_key].append(contextual_relevancy_score)\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "    return rag_test_cases\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0475f8999c1844968a56e7c0d2a10e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a28f193f3a4eb989d2b1414344f054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6ce40a072047a1aed72ebbc2c3c278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362612b5002d4116a20a73349bf4fca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96a2fc69af84e5e8949b1dbcad60119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:   5%|▌         | 1/20 [01:53<35:58, 113.63s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96957cdd56c404f8661beacb005843b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa4dc6d1e7d458289a384aab52fe4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9e511147464a34b79e93ff53e742eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ecc957c6524e3b832e3fc3440e47cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1fcad5fe2b4183b3574e07cbbb4b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  10%|█         | 2/20 [03:45<33:44, 112.46s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78f7c6f81714c9eb14fc5069eb3dc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6c1cc02b7b4bfdbc8831d394bd8afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700fdd70b2484efaab0a98181d2ab396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcfa82b757924e90ba705cb8d70199f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e8fd2c8efb4cacb0fba5ed85711738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  15%|█▌        | 3/20 [05:37<31:46, 112.16s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4da64a2cd0470a90b3413ba0712ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f89eb8d35147b6aa44984f6e82d00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c04e0d98ac4b69af9a9f0570a46885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aefcb5e8f6da4068b7fe5f81aae2a1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dff5f3c3704c069598134a866365c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  20%|██        | 4/20 [07:28<29:50, 111.90s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e7f7d166d94befb1dcde434bf7000d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5f8a6c91e74f62b1d2f38be4d5073e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f909113226495587158c1ce365db63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29db0afc14634ebcb532a0c837bf8252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4057d28f304812ae4597bc0e6d1edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  25%|██▌       | 5/20 [09:21<28:04, 112.31s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746e4f6cce454c1ab2e5e00d63cbf4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cadb9ceb28c4903b38b15f2ba9a44be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aacacae1d444272bd0806a05570a01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe0d305670e46e18320b20b678e413f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d76d643632445885e679b4ac61c8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  30%|███       | 6/20 [11:13<26:08, 112.06s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb53eac6f1ef45568e24dff81630f14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93f8c227bcc4494805ab2dc42194e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80eee688c1584a18b8747bee625e7e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c93cc821044793ad3240dbf49fafa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca90a0f1268420dbf05a0da4bc4d74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  35%|███▌      | 7/20 [13:09<24:36, 113.54s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203f76e503174f99b882d7a61ca0902a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515386ba0e12428684e5d9a02b134c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc012896a1f4a6382b9e0bddd4fdf9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17b58ff429248fa9a69ff0c8d378591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290ab5b06d2e488ebd1d981a82294775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  40%|████      | 8/20 [15:01<22:34, 112.89s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ede03d8423494890d7ac5026fad92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac0ce9c8353415a86f383d7b1cb5c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8adf49c8dc4b59bb89f087ae2bc645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b89609a6f684b7689014fc28eba11ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da2f768ee124fa1b6943ab4d5666e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  45%|████▌     | 9/20 [16:57<20:51, 113.80s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c8446da81746219da9d3cba58972df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f2eefbadbb468eba69985cc1da5779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f642d767586741319bb439afa37921f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8964f9707f4df4975a84aab4f558d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767ce00577904cbaad7db34ddb26c2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  50%|█████     | 10/20 [19:01<19:29, 116.97s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c262bfe0a12044c48e83f3044720d1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a29fc13b744d42b14283a4f7d322b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0c5e0349ed48d7b40a42ea07b53baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76db741e7c3543c3ace81b442bbcea1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7da5114b4ca4a41b39433373508c316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  55%|█████▌    | 11/20 [20:50<17:12, 114.72s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e44faa427c94401a27309bbf1958628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35003105644247bdb578af3f1761533b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549a072bb23944018992294cd830a4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8187cfc6cd14beabb19b83e9d109874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9167268a4e854a92b2e96afbd7ddc9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  60%|██████    | 12/20 [22:40<15:04, 113.12s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03b3adf69e14cd59b2ea8e35a8358f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b1eb3565c545ffa2b94f189593848d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b0cf28732d4b4c841e32703da2640f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99594347cbc04323a2acd9cc825b91e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080f3844c8bd424da6a38bfb9ae92fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  65%|██████▌   | 13/20 [24:32<13:10, 112.91s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1493e0da8e52435f800152a66779e662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289c6ad5dc9e411cb06e9762278d55de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e052acca8ec24041877834a39f52a218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7c2ba456544219bf5f7670ef6e92cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0b10dd8f6b4d21afe4edb3a8312c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  70%|███████   | 14/20 [26:23<11:13, 112.27s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f461872e55fd4dddb17870ab5840caf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59be3e4acdf4514b8484ba5c94abe53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7284d2f5b52b427dabf095ae910d0b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299df622f0d04677840dbb5cfc4aec87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128f02d341d4428ea07a6e0fb762e274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  75%|███████▌  | 15/20 [28:13<09:17, 111.50s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a9a9fc2fb448ad8192a7523d984fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 54.000000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d61c5226234fdd9a17808051d86244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f941df673a4e40e491a86f066b7a70a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f13dcb8ad604cef8c052741742af7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579f3e33185345669e2a6890dd07b103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  80%|████████  | 16/20 [30:55<08:26, 126.66s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdfeb3ecf2f48dc852aeb51963569a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6566b0bcf9f34e11a1fc84b02a3e9bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f484f4bcbe794e06b7cf0bc64c04f2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa9dd7dac514f8caec4227e507596a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfa249205a142f1b95583ce2dd6eb75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  85%|████████▌ | 17/20 [32:42<06:02, 120.82s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41489f3b4ba74e64a0403635b36beafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954d651a0e3348c3aa0d47eb11e2b4f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c3ee52aea64763a5b33ee70f98bd69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e4d786667b4c028d08f48eae05e119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a89d64fa3f4b21948d54f5ac84c8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  90%|█████████ | 18/20 [34:30<03:54, 117.12s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf70a833e8fa4c91bef99bc19ff636fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787e5c6829974996966aa3116d63aaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47178789dad4cc398702cfdaf037cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad83277c8ca844cca5cec67086456761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da310943ad34befa03e536804059316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers:  95%|█████████▌| 19/20 [36:17<01:54, 114.14s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933bc378f3104079a956d497c02b8911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85b9118a524436285cebf70b5b932b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 5.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa36c2a7f624ed8aa59e7b26db01978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb78d964bd04245b37f7c57574c1f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f6e67680504a6699ea350d8e1bf99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating answers: 100%|██████████| 20/20 [38:05<00:00, 114.25s/it]\n"
     ]
    }
   ],
   "source": [
    "adaptive_rag_test = evaluate_rag(\n",
    "    rag_test_cases=adaptive_rag_test,\n",
    "    answer_relevancy_key=\"answer_relevancy\",\n",
    "    faithfulness_key=\"faithfulness\",\n",
    "    contextual_precision_key=\"contextual_precision\",\n",
    "    contextual_recall_key=\"contextual_recall\",\n",
    "    contextual_relevancy_key=\"contextual_relevancy\",\n",
    "    question_key=\"question\",\n",
    "    expected_answer_key=\"expected_answer\",\n",
    "    actual_answer_key=\"adaptive_rag_answer\",\n",
    "    doc_context_key=\"adaptive_rag_doc_context\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['question', 'expected_answer', 'query_type', 'adaptive_rag_answer', 'adaptive_rag_doc_context', 'answer_relevancy', 'faithfulness', 'contextual_precision', 'contextual_recall', 'contextual_relevancy'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptive_rag_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_relevancy: 0.5944444444444444\n",
      "faithfulness: 0.47750000000000004\n",
      "contextual_precision: 0.38395833333333335\n",
      "contextual_recall: 0.22999999999999998\n",
      "contextual_relevancy: 0.2912545787545787\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f\"answer_relevancy: {np.average(adaptive_rag_test['answer_relevancy'])}\")\n",
    "print(f\"faithfulness: {np.average(adaptive_rag_test['faithfulness'])}\")\n",
    "print(f\"contextual_precision: {np.average(adaptive_rag_test['contextual_precision'])}\")\n",
    "print(f\"contextual_recall: {np.average(adaptive_rag_test['contextual_recall'])}\")\n",
    "print(f\"contextual_relevancy: {np.average(adaptive_rag_test['contextual_relevancy'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adaptive_rag_test.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(value=adaptive_rag_test, filename=\"adaptive_rag_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaredllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
